0
<torch.cuda.device object at 0x2aab1d54eeb8>
1
GeForce GTX TITAN X
True
2177
Beginning Training:
[32m[03/27 15:31:55 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=12, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=44, bias=True)
    )
  )
)
[32m[03/27 15:33:21 d2.data.build]: [0mRemoved 0 images with no usable annotations. 2177 images left.
[32m[03/27 15:33:21 d2.data.build]: [0mDistribution of instances among all 11 categories:
[36m|  category  | #instances   |   category    | #instances   |  category  | #instances   |
|:----------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|  barrier   | 2692         |    bicycle    | 274          |    bus     | 535          |
|    car     | 9437         | constructio.. | 247          | motorcycle | 543          |
| pedestrian | 5667         | traffic_cone  | 1574         |  trailer   | 63           |
|   truck    | 912          |     void      | 214          |            |              |
|   total    | 22158        |               |              |            |              |[0m
[32m[03/27 15:33:21 d2.data.common]: [0mSerializing 2177 elements to byte tensors and concatenating them all ...
[32m[03/27 15:33:21 d2.data.common]: [0mSerialized dataset takes 1.72 MiB
[32m[03/27 15:33:21 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/27 15:33:21 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/27 15:33:22 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[03/27 15:33:32 d2.utils.events]: [0m eta: 0:02:06  iter: 19  total_loss: 3.723  loss_cls: 2.486  loss_box_reg: 0.820  loss_rpn_cls: 0.196  loss_rpn_loc: 0.143  time: 0.4467  data_time: 0.0263  lr: 0.000005  max_mem: 2641M
[32m[03/27 15:33:41 d2.utils.events]: [0m eta: 0:01:57  iter: 39  total_loss: 3.360  loss_cls: 2.397  loss_box_reg: 0.700  loss_rpn_cls: 0.099  loss_rpn_loc: 0.070  time: 0.4476  data_time: 0.0057  lr: 0.000010  max_mem: 2641M
[32m[03/27 15:33:49 d2.utils.events]: [0m eta: 0:01:48  iter: 59  total_loss: 3.306  loss_cls: 2.215  loss_box_reg: 0.798  loss_rpn_cls: 0.208  loss_rpn_loc: 0.158  time: 0.4469  data_time: 0.0056  lr: 0.000015  max_mem: 2641M
[32m[03/27 15:33:59 d2.utils.events]: [0m eta: 0:01:39  iter: 79  total_loss: 3.183  loss_cls: 1.932  loss_box_reg: 0.844  loss_rpn_cls: 0.202  loss_rpn_loc: 0.074  time: 0.4479  data_time: 0.0068  lr: 0.000020  max_mem: 2641M
[32m[03/27 15:34:08 d2.utils.events]: [0m eta: 0:01:31  iter: 99  total_loss: 2.672  loss_cls: 1.615  loss_box_reg: 0.795  loss_rpn_cls: 0.183  loss_rpn_loc: 0.113  time: 0.4517  data_time: 0.0062  lr: 0.000025  max_mem: 2641M
[32m[03/27 15:34:17 d2.utils.events]: [0m eta: 0:01:22  iter: 119  total_loss: 2.243  loss_cls: 1.236  loss_box_reg: 0.697  loss_rpn_cls: 0.182  loss_rpn_loc: 0.123  time: 0.4504  data_time: 0.0058  lr: 0.000030  max_mem: 2641M
[32m[03/27 15:34:26 d2.utils.events]: [0m eta: 0:01:13  iter: 139  total_loss: 2.101  loss_cls: 1.050  loss_box_reg: 0.809  loss_rpn_cls: 0.123  loss_rpn_loc: 0.120  time: 0.4519  data_time: 0.0065  lr: 0.000035  max_mem: 2641M
[32m[03/27 15:34:35 d2.utils.events]: [0m eta: 0:01:04  iter: 159  total_loss: 1.949  loss_cls: 0.934  loss_box_reg: 0.804  loss_rpn_cls: 0.082  loss_rpn_loc: 0.074  time: 0.4526  data_time: 0.0056  lr: 0.000040  max_mem: 2641M
[32m[03/27 15:34:44 d2.utils.events]: [0m eta: 0:00:54  iter: 179  total_loss: 2.089  loss_cls: 0.935  loss_box_reg: 0.802  loss_rpn_cls: 0.103  loss_rpn_loc: 0.092  time: 0.4527  data_time: 0.0055  lr: 0.000045  max_mem: 2641M
[32m[03/27 15:34:54 d2.utils.events]: [0m eta: 0:00:46  iter: 199  total_loss: 1.862  loss_cls: 0.830  loss_box_reg: 0.808  loss_rpn_cls: 0.092  loss_rpn_loc: 0.097  time: 0.4562  data_time: 0.0059  lr: 0.000050  max_mem: 2641M
[32m[03/27 15:35:04 d2.utils.events]: [0m eta: 0:00:37  iter: 219  total_loss: 1.899  loss_cls: 0.744  loss_box_reg: 0.797  loss_rpn_cls: 0.167  loss_rpn_loc: 0.108  time: 0.4591  data_time: 0.0056  lr: 0.000055  max_mem: 2641M
[32m[03/27 15:35:13 d2.utils.events]: [0m eta: 0:00:28  iter: 239  total_loss: 1.935  loss_cls: 0.808  loss_box_reg: 0.795  loss_rpn_cls: 0.094  loss_rpn_loc: 0.105  time: 0.4607  data_time: 0.0062  lr: 0.000060  max_mem: 2641M
[32m[03/27 15:35:23 d2.utils.events]: [0m eta: 0:00:19  iter: 259  total_loss: 1.827  loss_cls: 0.815  loss_box_reg: 0.809  loss_rpn_cls: 0.121  loss_rpn_loc: 0.079  time: 0.4610  data_time: 0.0059  lr: 0.000065  max_mem: 2641M
[32m[03/27 15:35:32 d2.utils.events]: [0m eta: 0:00:09  iter: 279  total_loss: 1.775  loss_cls: 0.731  loss_box_reg: 0.829  loss_rpn_cls: 0.100  loss_rpn_loc: 0.096  time: 0.4615  data_time: 0.0058  lr: 0.000070  max_mem: 2641M
[32m[03/27 15:35:45 d2.utils.events]: [0m eta: 0:00:00  iter: 299  total_loss: 1.821  loss_cls: 0.703  loss_box_reg: 0.814  loss_rpn_cls: 0.109  loss_rpn_loc: 0.075  time: 0.4619  data_time: 0.0062  lr: 0.000075  max_mem: 2641M
[32m[03/27 15:35:45 d2.engine.hooks]: [0mOverall training speed: 297 iterations in 0:02:17 (0.4635 s / it)
[32m[03/27 15:35:45 d2.engine.hooks]: [0mTotal training time: 0:02:21 (0:00:03 on hooks)
Beginning Inference:
{'instances': Instances(num_instances=0, image_height=900, image_width=1600, fields=[pred_boxes: Boxes(tensor([], device='cuda:0', size=(0, 4))), scores: tensor([], device='cuda:0'), pred_classes: tensor([], device='cuda:0', dtype=torch.int64)])}
