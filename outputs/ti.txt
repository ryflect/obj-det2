0
<torch.cuda.device object at 0x2aab1d54ee80>
1
GeForce GTX TITAN X
True
2177
Beginning Training:
[32m[03/27 14:51:21 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=12, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=44, bias=True)
    )
  )
)
[32m[03/27 14:52:50 d2.data.build]: [0mRemoved 0 images with no usable annotations. 2177 images left.
[32m[03/27 14:52:50 d2.data.build]: [0mDistribution of instances among all 11 categories:
[36m|  category  | #instances   |   category    | #instances   |  category  | #instances   |
|:----------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|  barrier   | 2692         |    bicycle    | 274          |    bus     | 535          |
|    car     | 9437         | constructio.. | 247          | motorcycle | 543          |
| pedestrian | 5667         | traffic_cone  | 1574         |  trailer   | 63           |
|   truck    | 912          |     void      | 214          |            |              |
|   total    | 22158        |               |              |            |              |[0m
[32m[03/27 14:52:50 d2.data.common]: [0mSerializing 2177 elements to byte tensors and concatenating them all ...
[32m[03/27 14:52:50 d2.data.common]: [0mSerialized dataset takes 1.72 MiB
[32m[03/27 14:52:50 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/27 14:52:50 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/27 14:52:51 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[03/27 14:53:01 d2.utils.events]: [0m eta: 0:02:07  iter: 19  total_loss: 3.594  loss_cls: 2.475  loss_box_reg: 0.771  loss_rpn_cls: 0.268  loss_rpn_loc: 0.112  time: 0.4545  data_time: 0.0248  lr: 0.000005  max_mem: 2640M
[32m[03/27 14:53:10 d2.utils.events]: [0m eta: 0:01:58  iter: 39  total_loss: 3.523  loss_cls: 2.358  loss_box_reg: 0.727  loss_rpn_cls: 0.218  loss_rpn_loc: 0.080  time: 0.4519  data_time: 0.0065  lr: 0.000010  max_mem: 2640M
[32m[03/27 14:53:19 d2.utils.events]: [0m eta: 0:01:49  iter: 59  total_loss: 3.155  loss_cls: 2.183  loss_box_reg: 0.616  loss_rpn_cls: 0.122  loss_rpn_loc: 0.080  time: 0.4568  data_time: 0.0062  lr: 0.000015  max_mem: 2640M
[32m[03/27 14:53:28 d2.utils.events]: [0m eta: 0:01:41  iter: 79  total_loss: 2.961  loss_cls: 1.896  loss_box_reg: 0.840  loss_rpn_cls: 0.088  loss_rpn_loc: 0.080  time: 0.4616  data_time: 0.0062  lr: 0.000020  max_mem: 2640M
[32m[03/27 14:53:38 d2.utils.events]: [0m eta: 0:01:32  iter: 99  total_loss: 2.679  loss_cls: 1.583  loss_box_reg: 0.807  loss_rpn_cls: 0.127  loss_rpn_loc: 0.088  time: 0.4616  data_time: 0.0058  lr: 0.000025  max_mem: 2640M
[32m[03/27 14:53:47 d2.utils.events]: [0m eta: 0:01:23  iter: 119  total_loss: 2.210  loss_cls: 1.226  loss_box_reg: 0.783  loss_rpn_cls: 0.109  loss_rpn_loc: 0.071  time: 0.4622  data_time: 0.0059  lr: 0.000030  max_mem: 2640M
[32m[03/27 14:53:56 d2.utils.events]: [0m eta: 0:01:14  iter: 139  total_loss: 2.356  loss_cls: 1.090  loss_box_reg: 0.838  loss_rpn_cls: 0.227  loss_rpn_loc: 0.149  time: 0.4613  data_time: 0.0059  lr: 0.000035  max_mem: 2640M
[32m[03/27 14:54:05 d2.utils.events]: [0m eta: 0:01:05  iter: 159  total_loss: 1.588  loss_cls: 0.793  loss_box_reg: 0.632  loss_rpn_cls: 0.216  loss_rpn_loc: 0.148  time: 0.4618  data_time: 0.0076  lr: 0.000040  max_mem: 2640M
[32m[03/27 14:54:14 d2.utils.events]: [0m eta: 0:00:55  iter: 179  total_loss: 2.024  loss_cls: 0.869  loss_box_reg: 0.770  loss_rpn_cls: 0.190  loss_rpn_loc: 0.166  time: 0.4599  data_time: 0.0055  lr: 0.000045  max_mem: 2640M
[32m[03/27 14:54:24 d2.utils.events]: [0m eta: 0:00:46  iter: 199  total_loss: 1.765  loss_cls: 0.753  loss_box_reg: 0.722  loss_rpn_cls: 0.116  loss_rpn_loc: 0.094  time: 0.4626  data_time: 0.0055  lr: 0.000050  max_mem: 2640M
[32m[03/27 14:54:34 d2.utils.events]: [0m eta: 0:00:37  iter: 219  total_loss: 1.555  loss_cls: 0.765  loss_box_reg: 0.694  loss_rpn_cls: 0.084  loss_rpn_loc: 0.055  time: 0.4644  data_time: 0.0051  lr: 0.000055  max_mem: 2640M
[32m[03/27 14:54:43 d2.utils.events]: [0m eta: 0:00:28  iter: 239  total_loss: 1.725  loss_cls: 0.763  loss_box_reg: 0.807  loss_rpn_cls: 0.085  loss_rpn_loc: 0.069  time: 0.4637  data_time: 0.0057  lr: 0.000060  max_mem: 2640M
[32m[03/27 14:54:52 d2.utils.events]: [0m eta: 0:00:19  iter: 259  total_loss: 1.757  loss_cls: 0.720  loss_box_reg: 0.835  loss_rpn_cls: 0.078  loss_rpn_loc: 0.072  time: 0.4641  data_time: 0.0058  lr: 0.000065  max_mem: 2640M
[32m[03/27 14:55:02 d2.utils.events]: [0m eta: 0:00:09  iter: 279  total_loss: 1.727  loss_cls: 0.713  loss_box_reg: 0.816  loss_rpn_cls: 0.118  loss_rpn_loc: 0.092  time: 0.4654  data_time: 0.0053  lr: 0.000070  max_mem: 2640M
[32m[03/27 14:55:15 d2.utils.events]: [0m eta: 0:00:00  iter: 299  total_loss: 1.759  loss_cls: 0.709  loss_box_reg: 0.839  loss_rpn_cls: 0.118  loss_rpn_loc: 0.088  time: 0.4654  data_time: 0.0051  lr: 0.000075  max_mem: 2640M
[32m[03/27 14:55:15 d2.engine.hooks]: [0mOverall training speed: 297 iterations in 0:02:18 (0.4670 s / it)
[32m[03/27 14:55:15 d2.engine.hooks]: [0mTotal training time: 0:02:22 (0:00:03 on hooks)
Beginning Inference:
