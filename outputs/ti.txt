0
<torch.cuda.device object at 0x2aab1d54ee48>
1
GeForce GTX TITAN X
True
2177
Beginning Training:
[32m[03/27 15:22:06 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=12, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=44, bias=True)
    )
  )
)
[32m[03/27 15:23:45 d2.data.build]: [0mRemoved 0 images with no usable annotations. 2177 images left.
[32m[03/27 15:23:46 d2.data.build]: [0mDistribution of instances among all 11 categories:
[36m|  category  | #instances   |   category    | #instances   |  category  | #instances   |
|:----------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|  barrier   | 2692         |    bicycle    | 274          |    bus     | 535          |
|    car     | 9437         | constructio.. | 247          | motorcycle | 543          |
| pedestrian | 5667         | traffic_cone  | 1574         |  trailer   | 63           |
|   truck    | 912          |     void      | 214          |            |              |
|   total    | 22158        |               |              |            |              |[0m
[32m[03/27 15:23:46 d2.data.common]: [0mSerializing 2177 elements to byte tensors and concatenating them all ...
[32m[03/27 15:23:46 d2.data.common]: [0mSerialized dataset takes 1.72 MiB
[32m[03/27 15:23:46 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/27 15:23:46 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/27 15:23:47 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[03/27 15:23:57 d2.utils.events]: [0m eta: 0:02:13  iter: 19  total_loss: 3.735  loss_cls: 2.619  loss_box_reg: 0.808  loss_rpn_cls: 0.199  loss_rpn_loc: 0.093  time: 0.4670  data_time: 0.0328  lr: 0.000005  max_mem: 2643M
[32m[03/27 15:24:06 d2.utils.events]: [0m eta: 0:02:02  iter: 39  total_loss: 3.691  loss_cls: 2.526  loss_box_reg: 0.744  loss_rpn_cls: 0.266  loss_rpn_loc: 0.117  time: 0.4622  data_time: 0.0072  lr: 0.000010  max_mem: 2643M
[32m[03/27 15:24:16 d2.utils.events]: [0m eta: 0:01:53  iter: 59  total_loss: 3.459  loss_cls: 2.318  loss_box_reg: 0.831  loss_rpn_cls: 0.183  loss_rpn_loc: 0.104  time: 0.4632  data_time: 0.0070  lr: 0.000015  max_mem: 2643M
[32m[03/27 15:24:25 d2.utils.events]: [0m eta: 0:01:43  iter: 79  total_loss: 3.237  loss_cls: 2.005  loss_box_reg: 0.750  loss_rpn_cls: 0.377  loss_rpn_loc: 0.107  time: 0.4625  data_time: 0.0078  lr: 0.000020  max_mem: 2643M
[32m[03/27 15:24:35 d2.utils.events]: [0m eta: 0:01:35  iter: 99  total_loss: 2.762  loss_cls: 1.669  loss_box_reg: 0.781  loss_rpn_cls: 0.144  loss_rpn_loc: 0.100  time: 0.4675  data_time: 0.0071  lr: 0.000025  max_mem: 2643M
[32m[03/27 15:24:45 d2.utils.events]: [0m eta: 0:01:26  iter: 119  total_loss: 2.366  loss_cls: 1.308  loss_box_reg: 0.715  loss_rpn_cls: 0.138  loss_rpn_loc: 0.084  time: 0.4721  data_time: 0.0123  lr: 0.000030  max_mem: 2643M
[32m[03/27 15:24:55 d2.utils.events]: [0m eta: 0:01:16  iter: 139  total_loss: 2.106  loss_cls: 1.077  loss_box_reg: 0.839  loss_rpn_cls: 0.080  loss_rpn_loc: 0.058  time: 0.4795  data_time: 0.0131  lr: 0.000035  max_mem: 2643M
[32m[03/27 15:25:05 d2.utils.events]: [0m eta: 0:01:07  iter: 159  total_loss: 2.117  loss_cls: 0.974  loss_box_reg: 0.806  loss_rpn_cls: 0.167  loss_rpn_loc: 0.109  time: 0.4825  data_time: 0.0133  lr: 0.000040  max_mem: 2643M
[32m[03/27 15:25:15 d2.utils.events]: [0m eta: 0:00:58  iter: 179  total_loss: 1.835  loss_cls: 0.841  loss_box_reg: 0.789  loss_rpn_cls: 0.066  loss_rpn_loc: 0.038  time: 0.4850  data_time: 0.0102  lr: 0.000045  max_mem: 2643M
[32m[03/27 15:25:26 d2.utils.events]: [0m eta: 0:00:49  iter: 199  total_loss: 1.884  loss_cls: 0.836  loss_box_reg: 0.835  loss_rpn_cls: 0.070  loss_rpn_loc: 0.066  time: 0.4880  data_time: 0.0095  lr: 0.000050  max_mem: 2643M
[32m[03/27 15:25:36 d2.utils.events]: [0m eta: 0:00:39  iter: 219  total_loss: 1.716  loss_cls: 0.778  loss_box_reg: 0.804  loss_rpn_cls: 0.077  loss_rpn_loc: 0.071  time: 0.4898  data_time: 0.0087  lr: 0.000055  max_mem: 2643M
[32m[03/27 15:25:46 d2.utils.events]: [0m eta: 0:00:29  iter: 239  total_loss: 1.851  loss_cls: 0.743  loss_box_reg: 0.828  loss_rpn_cls: 0.126  loss_rpn_loc: 0.108  time: 0.4927  data_time: 0.0108  lr: 0.000060  max_mem: 2643M
[32m[03/27 15:25:57 d2.utils.events]: [0m eta: 0:00:20  iter: 259  total_loss: 1.563  loss_cls: 0.683  loss_box_reg: 0.779  loss_rpn_cls: 0.067  loss_rpn_loc: 0.043  time: 0.4944  data_time: 0.0120  lr: 0.000065  max_mem: 2643M
[32m[03/27 15:26:07 d2.utils.events]: [0m eta: 0:00:10  iter: 279  total_loss: 1.817  loss_cls: 0.735  loss_box_reg: 0.827  loss_rpn_cls: 0.090  loss_rpn_loc: 0.098  time: 0.4948  data_time: 0.0101  lr: 0.000070  max_mem: 2643M
[32m[03/27 15:26:20 d2.utils.events]: [0m eta: 0:00:00  iter: 299  total_loss: 1.648  loss_cls: 0.687  loss_box_reg: 0.763  loss_rpn_cls: 0.078  loss_rpn_loc: 0.087  time: 0.4942  data_time: 0.0087  lr: 0.000075  max_mem: 2643M
[32m[03/27 15:26:20 d2.engine.hooks]: [0mOverall training speed: 297 iterations in 0:02:27 (0.4959 s / it)
[32m[03/27 15:26:20 d2.engine.hooks]: [0mTotal training time: 0:02:31 (0:00:03 on hooks)
Beginning Inference:
