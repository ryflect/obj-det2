0
<torch.cuda.device object at 0x2aab161f34a8>
1
GeForce GTX TITAN X
True
2177
Beginning Training:
[32m[03/27 14:39:21 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=12, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=44, bias=True)
    )
  )
)
[32m[03/27 14:40:28 d2.data.build]: [0mRemoved 0 images with no usable annotations. 2177 images left.
[32m[03/27 14:40:28 d2.data.build]: [0mDistribution of instances among all 11 categories:
[36m|  category  | #instances   |   category    | #instances   |  category  | #instances   |
|:----------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|  barrier   | 2692         |    bicycle    | 274          |    bus     | 535          |
|    car     | 9437         | constructio.. | 247          | motorcycle | 543          |
| pedestrian | 5667         | traffic_cone  | 1574         |  trailer   | 63           |
|   truck    | 912          |     void      | 214          |            |              |
|   total    | 22158        |               |              |            |              |[0m
[32m[03/27 14:40:28 d2.data.common]: [0mSerializing 2177 elements to byte tensors and concatenating them all ...
[32m[03/27 14:40:28 d2.data.common]: [0mSerialized dataset takes 1.72 MiB
[32m[03/27 14:40:28 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/27 14:40:28 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/27 14:40:28 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[03/27 14:40:38 d2.utils.events]: [0m eta: 0:02:03  iter: 19  total_loss: 3.669  loss_cls: 2.369  loss_box_reg: 0.833  loss_rpn_cls: 0.412  loss_rpn_loc: 0.141  time: 0.4432  data_time: 0.0255  lr: 0.000005  max_mem: 2643M
[32m[03/27 14:40:47 d2.utils.events]: [0m eta: 0:01:55  iter: 39  total_loss: 3.443  loss_cls: 2.291  loss_box_reg: 0.834  loss_rpn_cls: 0.211  loss_rpn_loc: 0.116  time: 0.4426  data_time: 0.0052  lr: 0.000010  max_mem: 2643M
[32m[03/27 14:40:56 d2.utils.events]: [0m eta: 0:01:47  iter: 59  total_loss: 3.271  loss_cls: 2.106  loss_box_reg: 0.748  loss_rpn_cls: 0.213  loss_rpn_loc: 0.121  time: 0.4434  data_time: 0.0054  lr: 0.000015  max_mem: 2643M
[32m[03/27 14:41:05 d2.utils.events]: [0m eta: 0:01:38  iter: 79  total_loss: 2.652  loss_cls: 1.803  loss_box_reg: 0.687  loss_rpn_cls: 0.119  loss_rpn_loc: 0.061  time: 0.4446  data_time: 0.0051  lr: 0.000020  max_mem: 2643M
[32m[03/27 14:41:14 d2.utils.events]: [0m eta: 0:01:30  iter: 99  total_loss: 2.699  loss_cls: 1.523  loss_box_reg: 0.791  loss_rpn_cls: 0.186  loss_rpn_loc: 0.071  time: 0.4477  data_time: 0.0054  lr: 0.000025  max_mem: 2643M
[32m[03/27 14:41:23 d2.utils.events]: [0m eta: 0:01:21  iter: 119  total_loss: 2.215  loss_cls: 1.183  loss_box_reg: 0.782  loss_rpn_cls: 0.123  loss_rpn_loc: 0.116  time: 0.4469  data_time: 0.0055  lr: 0.000030  max_mem: 2643M
[32m[03/27 14:41:32 d2.utils.events]: [0m eta: 0:01:12  iter: 139  total_loss: 2.128  loss_cls: 0.990  loss_box_reg: 0.805  loss_rpn_cls: 0.151  loss_rpn_loc: 0.083  time: 0.4475  data_time: 0.0055  lr: 0.000035  max_mem: 2643M
[32m[03/27 14:41:41 d2.utils.events]: [0m eta: 0:01:03  iter: 159  total_loss: 1.976  loss_cls: 0.888  loss_box_reg: 0.843  loss_rpn_cls: 0.102  loss_rpn_loc: 0.086  time: 0.4484  data_time: 0.0052  lr: 0.000040  max_mem: 2643M
[32m[03/27 14:41:51 d2.utils.events]: [0m eta: 0:00:54  iter: 179  total_loss: 1.975  loss_cls: 0.879  loss_box_reg: 0.828  loss_rpn_cls: 0.139  loss_rpn_loc: 0.081  time: 0.4524  data_time: 0.0061  lr: 0.000045  max_mem: 2643M
[32m[03/27 14:42:00 d2.utils.events]: [0m eta: 0:00:46  iter: 199  total_loss: 1.948  loss_cls: 0.829  loss_box_reg: 0.765  loss_rpn_cls: 0.200  loss_rpn_loc: 0.081  time: 0.4561  data_time: 0.0054  lr: 0.000050  max_mem: 2643M
[32m[03/27 14:42:10 d2.utils.events]: [0m eta: 0:00:37  iter: 219  total_loss: 1.773  loss_cls: 0.737  loss_box_reg: 0.777  loss_rpn_cls: 0.089  loss_rpn_loc: 0.097  time: 0.4578  data_time: 0.0057  lr: 0.000055  max_mem: 2643M
[32m[03/27 14:42:19 d2.utils.events]: [0m eta: 0:00:28  iter: 239  total_loss: 1.638  loss_cls: 0.718  loss_box_reg: 0.749  loss_rpn_cls: 0.102  loss_rpn_loc: 0.099  time: 0.4594  data_time: 0.0051  lr: 0.000060  max_mem: 2643M
[32m[03/27 14:42:29 d2.utils.events]: [0m eta: 0:00:18  iter: 259  total_loss: 1.821  loss_cls: 0.673  loss_box_reg: 0.771  loss_rpn_cls: 0.092  loss_rpn_loc: 0.091  time: 0.4609  data_time: 0.0048  lr: 0.000065  max_mem: 2643M
[32m[03/27 14:42:39 d2.utils.events]: [0m eta: 0:00:09  iter: 279  total_loss: 1.696  loss_cls: 0.723  loss_box_reg: 0.848  loss_rpn_cls: 0.091  loss_rpn_loc: 0.094  time: 0.4625  data_time: 0.0054  lr: 0.000070  max_mem: 2643M
[32m[03/27 14:42:52 d2.utils.events]: [0m eta: 0:00:00  iter: 299  total_loss: 1.651  loss_cls: 0.697  loss_box_reg: 0.779  loss_rpn_cls: 0.070  loss_rpn_loc: 0.097  time: 0.4631  data_time: 0.0053  lr: 0.000075  max_mem: 2643M
[32m[03/27 14:42:52 d2.engine.hooks]: [0mOverall training speed: 297 iterations in 0:02:18 (0.4647 s / it)
[32m[03/27 14:42:52 d2.engine.hooks]: [0mTotal training time: 0:02:21 (0:00:03 on hooks)
