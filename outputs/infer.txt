0
<torch.cuda.device object at 0x2aab1d55a0f0>
1
GeForce GTX TITAN X
True
2177
Beginning Training:
[32m[03/31 23:04:24 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=12, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=44, bias=True)
    )
  )
)
[32m[03/31 23:05:41 d2.data.build]: [0mRemoved 0 images with no usable annotations. 2177 images left.
[32m[03/31 23:05:41 d2.data.build]: [0mDistribution of instances among all 11 categories:
[36m|  category  | #instances   |   category    | #instances   |  category  | #instances   |
|:----------:|:-------------|:-------------:|:-------------|:----------:|:-------------|
|  barrier   | 2692         |    bicycle    | 274          |    bus     | 535          |
|    car     | 9437         | constructio.. | 247          | motorcycle | 543          |
| pedestrian | 5667         | traffic_cone  | 1574         |  trailer   | 63           |
|   truck    | 912          |     void      | 214          |            |              |
|   total    | 22158        |               |              |            |              |[0m
[32m[03/31 23:05:41 d2.data.common]: [0mSerializing 2177 elements to byte tensors and concatenating them all ...
[32m[03/31 23:05:41 d2.data.common]: [0mSerialized dataset takes 1.72 MiB
[32m[03/31 23:05:41 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/31 23:05:41 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/31 23:05:45 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[03/31 23:05:56 d2.utils.events]: [0m eta: 0:02:11  iter: 19  total_loss: 3.566  loss_cls: 2.517  loss_box_reg: 0.722  loss_rpn_cls: 0.139  loss_rpn_loc: 0.106  time: 0.4642  data_time: 0.0320  lr: 0.000005  max_mem: 2643M
[32m[03/31 23:06:06 d2.utils.events]: [0m eta: 0:02:03  iter: 39  total_loss: 3.596  loss_cls: 2.412  loss_box_reg: 0.819  loss_rpn_cls: 0.200  loss_rpn_loc: 0.100  time: 0.4680  data_time: 0.0059  lr: 0.000010  max_mem: 2643M
[32m[03/31 23:06:15 d2.utils.events]: [0m eta: 0:01:54  iter: 59  total_loss: 3.263  loss_cls: 2.229  loss_box_reg: 0.847  loss_rpn_cls: 0.166  loss_rpn_loc: 0.078  time: 0.4741  data_time: 0.0080  lr: 0.000015  max_mem: 2643M
[32m[03/31 23:06:25 d2.utils.events]: [0m eta: 0:01:45  iter: 79  total_loss: 3.147  loss_cls: 1.970  loss_box_reg: 0.853  loss_rpn_cls: 0.118  loss_rpn_loc: 0.087  time: 0.4769  data_time: 0.0066  lr: 0.000020  max_mem: 2643M
[32m[03/31 23:06:35 d2.utils.events]: [0m eta: 0:01:37  iter: 99  total_loss: 2.656  loss_cls: 1.591  loss_box_reg: 0.804  loss_rpn_cls: 0.129  loss_rpn_loc: 0.101  time: 0.4840  data_time: 0.0060  lr: 0.000025  max_mem: 2643M
[32m[03/31 23:06:45 d2.utils.events]: [0m eta: 0:01:28  iter: 119  total_loss: 2.472  loss_cls: 1.304  loss_box_reg: 0.853  loss_rpn_cls: 0.119  loss_rpn_loc: 0.087  time: 0.4873  data_time: 0.0059  lr: 0.000030  max_mem: 2643M
[32m[03/31 23:06:56 d2.utils.events]: [0m eta: 0:01:18  iter: 139  total_loss: 2.157  loss_cls: 1.050  loss_box_reg: 0.831  loss_rpn_cls: 0.126  loss_rpn_loc: 0.097  time: 0.4911  data_time: 0.0058  lr: 0.000035  max_mem: 2643M
[32m[03/31 23:07:06 d2.utils.events]: [0m eta: 0:01:09  iter: 159  total_loss: 2.141  loss_cls: 0.909  loss_box_reg: 0.749  loss_rpn_cls: 0.216  loss_rpn_loc: 0.146  time: 0.4952  data_time: 0.0064  lr: 0.000040  max_mem: 2643M
[32m[03/31 23:07:17 d2.utils.events]: [0m eta: 0:01:00  iter: 179  total_loss: 1.952  loss_cls: 0.901  loss_box_reg: 0.846  loss_rpn_cls: 0.105  loss_rpn_loc: 0.112  time: 0.4975  data_time: 0.0065  lr: 0.000045  max_mem: 2643M
[32m[03/31 23:07:27 d2.utils.events]: [0m eta: 0:00:50  iter: 199  total_loss: 1.940  loss_cls: 0.837  loss_box_reg: 0.771  loss_rpn_cls: 0.159  loss_rpn_loc: 0.110  time: 0.4997  data_time: 0.0067  lr: 0.000050  max_mem: 2643M
[32m[03/31 23:07:39 d2.utils.events]: [0m eta: 0:00:40  iter: 219  total_loss: 1.813  loss_cls: 0.774  loss_box_reg: 0.766  loss_rpn_cls: 0.102  loss_rpn_loc: 0.075  time: 0.5091  data_time: 0.0060  lr: 0.000055  max_mem: 2643M
[32m[03/31 23:07:51 d2.utils.events]: [0m eta: 0:00:31  iter: 239  total_loss: 1.719  loss_cls: 0.743  loss_box_reg: 0.801  loss_rpn_cls: 0.086  loss_rpn_loc: 0.075  time: 0.5187  data_time: 0.0081  lr: 0.000060  max_mem: 2643M
[32m[03/31 23:08:05 d2.utils.events]: [0m eta: 0:00:21  iter: 259  total_loss: 1.734  loss_cls: 0.721  loss_box_reg: 0.804  loss_rpn_cls: 0.148  loss_rpn_loc: 0.091  time: 0.5293  data_time: 0.0059  lr: 0.000065  max_mem: 2643M
[32m[03/31 23:08:19 d2.utils.events]: [0m eta: 0:00:10  iter: 279  total_loss: 1.829  loss_cls: 0.754  loss_box_reg: 0.822  loss_rpn_cls: 0.111  loss_rpn_loc: 0.076  time: 0.5420  data_time: 0.0076  lr: 0.000070  max_mem: 2643M
[32m[03/31 23:08:36 d2.utils.events]: [0m eta: 0:00:00  iter: 299  total_loss: 1.823  loss_cls: 0.759  loss_box_reg: 0.839  loss_rpn_cls: 0.115  loss_rpn_loc: 0.090  time: 0.5524  data_time: 0.0060  lr: 0.000075  max_mem: 2643M
[32m[03/31 23:08:36 d2.engine.hooks]: [0mOverall training speed: 297 iterations in 0:02:44 (0.5543 s / it)
[32m[03/31 23:08:36 d2.engine.hooks]: [0mTotal training time: 0:02:48 (0:00:03 on hooks)
Beginning Inference:
{'instances': Instances(num_instances=0, image_height=900, image_width=1600, fields=[pred_boxes: Boxes(tensor([], device='cuda:0', size=(0, 4))), scores: tensor([], device='cuda:0'), pred_classes: tensor([], device='cuda:0', dtype=torch.int64)])}
